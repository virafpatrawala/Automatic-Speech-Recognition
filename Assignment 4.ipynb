{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write, read\n",
    "import control\n",
    "import os\n",
    "from scipy.fftpack import fft, dct\n",
    "from scipy.cluster.vq import vq, kmeans, whiten\n",
    "from python_speech_features import mfcc #To compare\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_emphasis(x, alpha):\n",
    "    y=np.zeros((x.size,))\n",
    "    y[0]=x[0]\n",
    "    for i in range(1,x.size):\n",
    "        y[i]=x[i]-alpha*x[i-1]\n",
    "    return y\n",
    "\n",
    "def get_STE(signal, nFrames, sampsPerFrame):\n",
    "    STEs = []  # list of short-time energies\n",
    "    for k in range(nFrames):\n",
    "        startIdx = k*sampsPerFrame\n",
    "        stopIdx = startIdx + sampsPerFrame\n",
    "        window = zeros(signal.shape)\n",
    "        window[startIdx:stopIdx] = np.hamming(sampsPerFrame)  # Hamming window\n",
    "        STE = sum((signal**2)*(window**2))\n",
    "        STEs.append(STE)\n",
    "    return STEs\n",
    "\n",
    "def end_pointer(signal, STEs, n):\n",
    "    folder='./cut_gender_separated_data/Female/'\n",
    "    digits = ['0','0','1','1','2','2','3','3','4','4','5','5',\n",
    "             '6','6','7','7','8','8','9','9']\n",
    "    width_phone = 18  #For simplicity fix length of all phones \n",
    "    frame=8  #Start analysis from this frame\n",
    "    count=0\n",
    "    while(frame<len(STEs)):\n",
    "        if(STEs[frame]>=0.5):  #When over a threshold \n",
    "            sound=signal1[(frame-2)*sampsPerFrame:(frame+width_phone)*sampsPerFrame]  #Extract signal of width 20 frames\n",
    "            write(folder + digits[count] + '/digit_{}_{}_{}.wav'.format(digits[count], n, count%2), 8000, sound)\n",
    "            frame+=27  #Skip certain amount onto further analysis\n",
    "            count+=1\n",
    "        else: frame+=1\n",
    "    print(count)\n",
    "    \n",
    "def mel_freq(f):\n",
    "    return 2595*np.log10(1 + (f/700))\n",
    "\n",
    "def mel_inv(f):\n",
    "    return 700*(10**(f/2595)-1)\n",
    "\n",
    "def mel_bins(f_start, f_end, nfilts, fs):\n",
    "    f_start_mel = mel_freq(f_start)\n",
    "    f_end_mel = mel_freq(f_end)\n",
    "    f=np.linspace(f_start_mel, f_end_mel, nfilts+2)\n",
    "    for i in range(f.shape[0]):\n",
    "        f[i]=mel_inv(f[i])\n",
    "        f[i]=np.floor((257)*f[i]/fs)\n",
    "    return f\n",
    "\n",
    "def mel_filterbank(f, nfilts):\n",
    "    fbank = np.zeros([nfilts,512//2+1])\n",
    "    for m in range(nfilts):\n",
    "        for k in range(int(f[m]), int(f[m+1])):\n",
    "            fbank[m,k] = (k - f[m]) / (f[m+1]-f[m])\n",
    "        for k in range(int(f[m+1]), int(f[m+2])):\n",
    "            fbank[m,k] = (f[m+2]-k) / (f[m+2]-f[m+1])\n",
    "    return fbank\n",
    "\n",
    "def feature_extractor(digit):\n",
    "    features = []  # list of MFCC features\n",
    "    fs=8000\n",
    "    nfilts=26\n",
    "    \n",
    "    window_length = 10  #in ms\n",
    "    sampsPerFrame = int(window_length*fs/1000)\n",
    "    nFrames = int(len(digit)/sampsPerFrame)\n",
    "    \n",
    "    for k in range(nFrames):\n",
    "        startIdx = k*sampsPerFrame\n",
    "        stopIdx = startIdx + sampsPerFrame\n",
    "        window = np.hamming(sampsPerFrame)  # Hamming window\n",
    "        frame = window*digit[startIdx:stopIdx]\n",
    "        frame_fft = np.fft.fft(frame, n=512) #Compute a 512 point DFT\n",
    "        p=(np.abs(frame_fft)**2)/frame.shape[0] #Compute the Periodogram\n",
    "        \n",
    "        bins = mel_bins(300, 4000, nfilts, fs) \n",
    "        fbank = mel_filterbank(bins, nfilts)  #Creating the Mel Filterbank\n",
    "        c=np.dot(p[:257],fbank.T) \n",
    "        c=20*log10(c)  \n",
    "        c=dct(c)  #Discrete Cosine Transform\n",
    "        features.append(c[:13])\n",
    "\n",
    "    return features\n",
    "\n",
    "def get_accuracy(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return 100.0*correct/len(actual)\n",
    "\n",
    "def euclidean_distance(v1, v2):\n",
    "    distance = 0.0\n",
    "    for i in range(v1.shape[0]):\n",
    "        distance += (v1[i] - v2[i])**2\n",
    "    return sqrt(distance)\n",
    "\n",
    "def vq_codebook(codebook, clusters):\n",
    "    vq_cb=np.zeros((codebook.shape[0],clusters,codebook.shape[2]))\n",
    "    for i in range(codebook.shape[0]):\n",
    "        vq_cb[i] = kmeans(codebook[i],clusters)[0]\n",
    "    return vq_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### QUESTION 1 #########\n",
    "\n",
    "directory = './CA4-data/'\n",
    "done=0\n",
    "for file in os.listdir(directory):\n",
    "    fs, signal1 = read(directory+file)\n",
    "    signal = signal1/max(abs(signal1))  #Scale the audio file\n",
    "\n",
    "    # For a window with sampling frequency fs\n",
    "    window_length = 30  #in ms\n",
    "    sampsPerFrame = int(window_length*fs/1000)\n",
    "    nFrames = int(len(signal)/sampsPerFrame)\n",
    "    \n",
    "    # Get the STE of the input signal\n",
    "    STEs=get_STE(signal, nFrames, sampsPerFrame)\n",
    "    \n",
    "    # Cut the digits and save in the respective folder\n",
    "    end_pointer(signal1, STEs, done)\n",
    "    \n",
    "    done+=1\n",
    "    print(\"Done: \", done, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='./CA4-data/zero_to_nine_Shradha1.wav'\n",
    "\n",
    "fs, signal1 = read(file)\n",
    "signal = signal1/max(abs(signal1))  #Scale the audio file\n",
    "\n",
    "# For a window with sampling frequency fs\n",
    "window_length = 30  #in ms\n",
    "sampsPerFrame = int(window_length*fs/1000)\n",
    "nFrames = int(len(signal)/sampsPerFrame)\n",
    "\n",
    "STEs=get_STE(signal, nFrames, sampsPerFrame)\n",
    "plt.plot(STEs[:15])\n",
    "plt.title('Short-Time Energy')\n",
    "plt.ylabel('ENERGY')\n",
    "plt.xlabel('FRAME')\n",
    "\n",
    "width_phone=18\n",
    "frame=7\n",
    "count=0\n",
    "while(frame<len(STEs)):\n",
    "    if(STEs[frame]>=0.5):\n",
    "        count+=1\n",
    "        sound=signal1[(frame-2)*sampsPerFrame:(frame+width_phone)*sampsPerFrame]\n",
    "        write('./sounds/test_{}.wav'.format(frame), 8000, sound)\n",
    "        frame+=27\n",
    "    else: frame+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Question 2 ###########\n",
    "\n",
    "file1 ='./cut_dataset/7/digit_7_0_0.wav'\n",
    "\n",
    "fs, digit1 = read(file1)\n",
    "digit = digit1/max(abs(digit1))  #Scale the audio file\n",
    "\n",
    "features=np.array(feature_extractor(digit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Question 3 ##########\n",
    "# Creating a codebook with training data\n",
    "directory = './cut_dataset/'\n",
    "codebook = np.zeros((10,108*60,13))\n",
    "for label in range(10):  #Iterate over each digit\n",
    "    folder = os.path.join(directory,str(label)+'/')\n",
    "    i=0\n",
    "    for file in os.listdir(folder):\n",
    "        fs, digit1 = read(folder+file)\n",
    "        digit = digit1/max(abs(digit1))  #Scale the audio file\n",
    "        features=np.array(feature_extractor(digit))\n",
    "        codebook[label,i*60:(i+1)*60,:] = features\n",
    "        i+=1\n",
    "    print('done', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits a codebook with all data into training and test data\n",
    "# Test ranges from 0 to 27\n",
    "def split_codebook(codebook, test): \n",
    "    train_codebook = np.zeros((codebook.shape[0],codebook.shape[1]-(4*60),codebook.shape[2]))\n",
    "    testset = np.zeros((codebook.shape[0],4*60,codebook.shape[2]))\n",
    "    for label in range(10):  #Iterate over each digit\n",
    "        i=0\n",
    "        j=0\n",
    "        for count in range(codebook.shape[1]//60):\n",
    "            if(count < 4*test or count >= 4*test+4): #if does not belong to test set add to codebook\n",
    "                train_codebook[label,i*60:(i+1)*60,:] = codebook[label,count*60:(count+1)*60,:]\n",
    "                i+=1\n",
    "            else: #add to test set\n",
    "                testset[label,j*60:(j+1)*60,:] = codebook[label,count*60:(count+1)*60,:]\n",
    "                j+=1             \n",
    "    return codebook, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_features(features, vq_cb):\n",
    "    min_distance=100000000 \n",
    "    pred=10\n",
    "    for label in range(vq_cb.shape[0]):  #Iterate overall all digit vector clouds\n",
    "        d_label=0\n",
    "        for i in range(features.shape[0]):  #For the ith frame of test sample\n",
    "            d_min=10000000\n",
    "            for k in range(vq_cb.shape[1]):  #Compare it with the K vectors per digit\n",
    "                d = euclidean_distance(features[i],vq_cb[label,k])  #Calculate Euclidean distance\n",
    "                if(d<d_min):\n",
    "                    d_min=d\n",
    "            d_label +=d_min  #Accumulate minimum Euclidean distances for all frames of test sample\n",
    "        d_label/=60  #Average out \n",
    "        if(d_label < min_distance):\n",
    "            min_distance = d_label\n",
    "            pred = label\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "k_list = [4, 8, 16, 64]\n",
    "for K in k_list:\n",
    "    pred_list = []\n",
    "    target_list = []\n",
    "    for test in range(27):\n",
    "        cb, testset = split_codebook(codebook, test)\n",
    "        cb = vq_codebook(cb, K)\n",
    "        directory = './cut_dataset/'\n",
    "        for label in range(10):  #Iterate over each digit\n",
    "            for i in range(4):\n",
    "                test_features = testset[label, i*60:(i+1)*60:]\n",
    "                pred = predict_with_features(test_features, cb)\n",
    "                pred_list.append(pred)\n",
    "                target_list.append(label)\n",
    "                total+=1\n",
    "    accuracy = get_accuracy(target_list, pred_list)\n",
    "    accuracy_list.append(accuracy)    \n",
    "    print('For {} clusters:'.format(K), \"Accuracy = \", accuracy)\n",
    "    conf = confusion_matrix(target_list, pred_list)\n",
    "    print(conf)\n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.title(\"Accuracy vs K clusters\")\n",
    "plt.xlabel('K clusters')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(k_list, accuracy_list)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.title(\"WER (%) vs K clusters\")\n",
    "plt.xlabel('K clusters')\n",
    "plt.ylabel('WER')\n",
    "plt.plot(k_list, list(np.array([100,100,100,100])-np.array(accuracy_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dynamic_features(digit):\n",
    "    mfcc_features = np.array(feature_extractor(digit))\n",
    "    dynamic_features = np.zeros((mfcc_features.shape[0], mfcc_features.shape[1]*3))\n",
    "    dynamic_features[:,:13] = mfcc_features\n",
    "    dynamic_features[:,13:26] = mfcc_features\n",
    "    dynamic_features[:,26:39] = mfcc_features\n",
    "    for j in range(1,12):\n",
    "        dynamic_features[:,13+j] = (mfcc_features[:,j+1] - mfcc_features[:,j-1])/2.0\n",
    "    for j in range(2,11):\n",
    "        dynamic_features[:,26+j] = (mfcc_features[:,j+2] - mfcc_features[:,j-2])/2.0\n",
    "    return dynamic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(get_dynamic_features(digit))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Question 4 ############\n",
    "# Creating a codebook with 39 features + Pre Emphasis\n",
    "directory = './cut_dataset/'\n",
    "codebook_1 = np.zeros((10,108*60,39))\n",
    "for label in range(10):  #Iterate over each digit\n",
    "    folder = os.path.join(directory,str(label)+'/')\n",
    "    i=0\n",
    "    for file in os.listdir(folder):\n",
    "        fs, digit1 = read(folder+file)\n",
    "        digit = digit1/max(abs(digit1))  #Scale the audio file\n",
    "        digit = pre_emphasis(digit, 0.9)  #Pre emphasis of 0.9 alpha\n",
    "        features=get_dynamic_features(digit)\n",
    "        codebook_1[label,i*60:(i+1)*60,:] = features\n",
    "        i+=1\n",
    "    print('done', label)\n",
    "\n",
    "pred_list = []\n",
    "target_list = []\n",
    "for test in range(27):\n",
    "    cb, testset = split_codebook(codebook_1, test)\n",
    "    cb = vq_codebook(cb, 64)\n",
    "    directory = './cut_dataset/'\n",
    "    for label in range(10):  #Iterate over each digit\n",
    "        for i in range(4):\n",
    "            test_features = testset[label, i*60:(i+1)*60:]\n",
    "            pred = predict_with_features(test_features, cb)\n",
    "            pred_list.append(pred)\n",
    "            target_list.append(label)\n",
    "            total+=1\n",
    "accuracy = get_accuracy(target_list, pred_list)  \n",
    "print(\"\\nAccuracy = \", accuracy)\n",
    "conf = confusion_matrix(target_list, pred_list)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a codebook with 13 features on PRE EMPHASISED SOUND\n",
    "directory = './cut_dataset/'\n",
    "codebook_2 = np.zeros((10,108*60,13))\n",
    "for label in range(10):  #Iterate over each digit\n",
    "    folder = os.path.join(directory,str(label)+'/')\n",
    "    i=0\n",
    "    for file in os.listdir(folder):\n",
    "        fs, digit1 = read(folder+file)\n",
    "        digit = digit1/max(abs(digit1))  #Scale the audio file\n",
    "        digit = pre_emphasis(digit, 0.9)  #Pre emphasis of 0.9 alpha\n",
    "        features=np.array(feature_extractor(digit))\n",
    "        codebook_2[label,i*60:(i+1)*60,:] = features\n",
    "        i+=1\n",
    "    print('done', label)\n",
    "\n",
    "pred_list = []\n",
    "target_list = []\n",
    "for test in range(27):\n",
    "    cb, testset = split_codebook(codebook_2, test)\n",
    "    cb = vq_codebook(cb, 64)\n",
    "    directory = './cut_dataset/'\n",
    "    for label in range(10):  #Iterate over each digit\n",
    "        for i in range(4):\n",
    "            test_features = testset[label, i*60:(i+1)*60:]\n",
    "            pred = predict_with_features(test_features, cb)\n",
    "            pred_list.append(pred)\n",
    "            target_list.append(label)\n",
    "            total+=1\n",
    "accuracy = get_accuracy(target_list, pred_list)  \n",
    "print(\"\\nAccuracy = \", accuracy)\n",
    "conf = confusion_matrix(target_list, pred_list)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a codebook with 13 dynamic features (delta delta mfccs)\n",
    "directory = './cut_dataset/'\n",
    "codebook_3 = np.zeros((10,108*60,13))\n",
    "for label in range(10):  #Iterate over each digit\n",
    "    folder = os.path.join(directory,str(label)+'/')\n",
    "    i=0\n",
    "    for file in os.listdir(folder):\n",
    "        fs, digit1 = read(folder+file)\n",
    "        digit = digit1/max(abs(digit1))  #Scale the audio file\n",
    "        features=get_dynamic_features(digit)[:,26:39]\n",
    "        codebook_3[label,i*60:(i+1)*60,:] = features\n",
    "        i+=1\n",
    "    print('done', label)\n",
    "\n",
    "pred_list = []\n",
    "target_list = []\n",
    "for test in range(27):\n",
    "    cb, testset = split_codebook(codebook_3, test)\n",
    "    cb = vq_codebook(cb, 64)\n",
    "    directory = './cut_dataset/'\n",
    "    for label in range(10):  #Iterate over each digit\n",
    "        for i in range(4):\n",
    "            test_features = testset[label, i*60:(i+1)*60:]\n",
    "            pred = predict_with_features(test_features, cb)\n",
    "            pred_list.append(pred)\n",
    "            target_list.append(label)\n",
    "            total+=1\n",
    "accuracy = get_accuracy(target_list, pred_list)  \n",
    "print(\"\\nAccuracy = \", accuracy)\n",
    "conf = confusion_matrix(target_list, pred_list)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Gender based separation in data\n",
    "\n",
    "directory = './Digits_female/'\n",
    "done=0\n",
    "for file in os.listdir(directory):\n",
    "    fs, signal1 = read(directory+file)\n",
    "    signal = signal1/max(abs(signal1))  #Scale the audio file\n",
    "\n",
    "    # For a window with sampling frequency fs\n",
    "    window_length = 30  #in ms\n",
    "    sampsPerFrame = int(window_length*fs/1000)\n",
    "    nFrames = int(len(signal)/sampsPerFrame)\n",
    "    \n",
    "    # Get the STE of the input signal\n",
    "    STEs=get_STE(signal, nFrames, sampsPerFrame)\n",
    "    \n",
    "    # Cut the digits and save in the respective folder\n",
    "    end_pointer(signal1, STEs, done)\n",
    "    \n",
    "    done+=1\n",
    "    print(\"Done: \", done, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './cut_gender_separated_data/Male'\n",
    "codebook_male = np.zeros((10,68*60,13))\n",
    "for label in range(10):  #Iterate over each digit\n",
    "    folder = os.path.join(directory,str(label)+'/')\n",
    "    i=0\n",
    "    for file in os.listdir(folder):\n",
    "        fs, digit1 = read(folder+file)\n",
    "        digit = digit1/max(abs(digit1))  #Scale the audio file\n",
    "        features=np.array(feature_extractor(digit))\n",
    "        codebook_male[label,i*60:(i+1)*60,:] = features\n",
    "        i+=1\n",
    "    print('done', label)\n",
    "\n",
    "directory = './cut_gender_separated_data/Female'\n",
    "codebook_female = np.zeros((10,40*60,13))\n",
    "for label in range(10):  #Iterate over each digit\n",
    "    folder = os.path.join(directory,str(label)+'/')\n",
    "    i=0\n",
    "    for file in os.listdir(folder):\n",
    "        fs, digit1 = read(folder+file)\n",
    "        digit = digit1/max(abs(digit1))  #Scale the audio file\n",
    "        features=np.array(feature_extractor(digit))\n",
    "        codebook_female[label,i*60:(i+1)*60,:] = features\n",
    "        i+=1\n",
    "    print('done', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Training data: Males, Testing data: Males ########\n",
    "print('Training data: Males, Testing data: Males\\n')\n",
    "pred_list = []\n",
    "target_list = []\n",
    "for test in range(17):\n",
    "    cb, testset = split_codebook(codebook_male, test)\n",
    "    cb = vq_codebook(cb, 64)\n",
    "    directory = './cut_dataset/'\n",
    "    for label in range(10):  #Iterate over each digit\n",
    "        for i in range(4):\n",
    "            test_features = testset[label, i*60:(i+1)*60:]\n",
    "            pred = predict_with_features(test_features, cb)\n",
    "            pred_list.append(pred)\n",
    "            target_list.append(label)\n",
    "            total+=1\n",
    "accuracy = get_accuracy(target_list, pred_list)  \n",
    "print(\"\\nAccuracy = \", accuracy)\n",
    "conf = confusion_matrix(target_list, pred_list)\n",
    "print(conf)\n",
    "\n",
    "#### Training data: Females, Testing data: Females ########\n",
    "print('\\nTraining data: Females, Testing data: Females\\n')\n",
    "pred_list = []\n",
    "target_list = []\n",
    "for test in range(10):\n",
    "    cb, testset = split_codebook(codebook_female, test)\n",
    "    cb = vq_codebook(cb, 64)\n",
    "    directory = './cut_dataset/'\n",
    "    for label in range(10):  #Iterate over each digit\n",
    "        for i in range(4):\n",
    "            test_features = testset[label, i*60:(i+1)*60:]\n",
    "            pred = predict_with_features(test_features, cb)\n",
    "            pred_list.append(pred)\n",
    "            target_list.append(label)\n",
    "            total+=1\n",
    "accuracy = get_accuracy(target_list, pred_list)  \n",
    "print(\"\\nAccuracy = \", accuracy)\n",
    "conf = confusion_matrix(target_list, pred_list)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Training data: Males, Testing data: Females ########\n",
    "print('Training data: Males, Testing data: Females\\n')\n",
    "pred_list = []\n",
    "target_list = []\n",
    "for test in range(10):\n",
    "    _, testset = split_codebook(codebook_female, test)\n",
    "    cb = codebook_male\n",
    "    cb = vq_codebook(cb, 64)\n",
    "    directory = './cut_dataset/'\n",
    "    for label in range(10):  #Iterate over each digit\n",
    "        for i in range(4):\n",
    "            test_features = testset[label, i*60:(i+1)*60:]\n",
    "            pred = predict_with_features(test_features, cb)\n",
    "            pred_list.append(pred)\n",
    "            target_list.append(label)\n",
    "            total+=1\n",
    "accuracy = get_accuracy(target_list, pred_list)  \n",
    "print(\"\\nAccuracy = \", accuracy)\n",
    "conf = confusion_matrix(target_list, pred_list)\n",
    "print(conf)\n",
    "\n",
    "#### Training data: Females, Testing data: Males ########\n",
    "print('Training data: Females, Testing data: Males\\n')\n",
    "pred_list = []\n",
    "target_list = []\n",
    "for test in range(17):\n",
    "    _, testset = split_codebook(codebook_male, test)\n",
    "    cb = codebook_female\n",
    "    cb = vq_codebook(cb, 64)\n",
    "    directory = './cut_dataset/'\n",
    "    for label in range(10):  #Iterate over each digit\n",
    "        for i in range(4):\n",
    "            test_features = testset[label, i*60:(i+1)*60:]\n",
    "            pred = predict_with_features(test_features, cb)\n",
    "            pred_list.append(pred)\n",
    "            target_list.append(label)\n",
    "            total+=1\n",
    "accuracy = get_accuracy(target_list, pred_list)  \n",
    "print(\"\\nAccuracy = \", accuracy)\n",
    "conf = confusion_matrix(target_list, pred_list)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_cost_plot(distances):\n",
    "    im = plt.imshow(distances, interpolation='nearest', cmap='Blues') \n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"Template Features\")\n",
    "    plt.ylabel(\"Test Features\")\n",
    "    plt.grid()\n",
    "    plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_cost(x, y, accumulated_cost, distances):\n",
    "    #Maps frames between x and y for minimum cost\n",
    "    path = [[len(x)-1, len(y)-1]]\n",
    "    cost = 0\n",
    "    i = len(x)-1\n",
    "    j = len(y)-1\n",
    "    while i>0 and j>0:\n",
    "        if i==0:\n",
    "            j = j - 1\n",
    "        elif j==0:\n",
    "            i = i - 1\n",
    "        else:\n",
    "            if accumulated_cost[i-1, j] == min(accumulated_cost[i-1, j-1],\n",
    "                                               accumulated_cost[i-1, j], accumulated_cost[i, j-1]):\n",
    "                i = i - 1\n",
    "            if accumulated_cost[i, j-1] == min(accumulated_cost[i-1, j-1],\n",
    "                                               accumulated_cost[i-1, j], accumulated_cost[i, j-1]):\n",
    "                j = j-1\n",
    "            else:\n",
    "                i = i - 1\n",
    "                j = j - 1\n",
    "        path.append([i, j])\n",
    "    path.append([0,0])\n",
    "    for [x, y] in path:\n",
    "        cost = cost + distances[x, y]\n",
    "    return path, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_time_warping(template_features, test_features):\n",
    "    x=template_features\n",
    "    y=test_features\n",
    "    distances = np.zeros((len(x), len(y)))\n",
    "    \n",
    "    #Create a distance matrix for all combinations of test and template frames\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(y)):\n",
    "            distances[i,j] = euclidean_distance(x[i],y[j])\n",
    "    \n",
    "    #Develop the accumulated cost array i.e. the minimum total cost to get to a point x,y\n",
    "    accumulated_cost = np.zeros((len(x), len(y)))\n",
    "    accumulated_cost[0,0] = distances[0,0]\n",
    "    for i in range(1, len(y)):\n",
    "        accumulated_cost[0,i] = distances[0,i] + accumulated_cost[0, i-1] \n",
    "    for i in range(1, len(x)):\n",
    "        accumulated_cost[i,0] = distances[i, 0] + accumulated_cost[i-1, 0]    \n",
    "    for i in range(1, len(x)):\n",
    "        for j in range(1, len(y)):\n",
    "            accumulated_cost[i, j] = min(accumulated_cost[i-1, j-1],\n",
    "                                         accumulated_cost[i-1, j], accumulated_cost[i, j-1]) + distances[i, j]\n",
    "            \n",
    "    path, cost = path_cost(x, y, accumulated_cost, distances)      \n",
    "    \n",
    "#     path_x = [point[0] for point in path]\n",
    "#     path_y = [point[1] for point in path]\n",
    "\n",
    "#     distance_cost_plot(accumulated_cost)\n",
    "#     plt.plot(path_x, path_y, 'r-')\n",
    "    \n",
    "    return path, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 ='./cut_dataset/1/digit_1_37_1.wav'\n",
    "file2 ='./cut_dataset/1/digit_1_37_1.wav'\n",
    "_, digit1 = read(file1)\n",
    "_, digit2 = read(file2)\n",
    "\n",
    "template = np.array(feature_extractor(digit1/max(abs(digit1))))\n",
    "test = np.array(feature_extractor(digit2/max(abs(digit2))))\n",
    "\n",
    "path,cost= dynamic_time_warping(template, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cost)\n",
    "print(len(path))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_DTW(test_features, cb):\n",
    "    min_distance=100000000 \n",
    "    pred=10\n",
    "    for label in range(cb.shape[0]):  #Iterate overall all digit vector clouds\n",
    "        d_label=0\n",
    "        d_min=10000000\n",
    "        for i in range(3):  #Compare with 3 random template samples from the class\n",
    "            n = random.randint(0,103)\n",
    "            template_features = cb[label, n*60:(n+1)*60,:]\n",
    "            _, cost = dynamic_time_warping(template_features, test_features) \n",
    "            if(cost<d_min):\n",
    "                d_min = cost\n",
    "        d_label = d_min\n",
    "        if(d_label < min_distance):\n",
    "            min_distance = d_label\n",
    "            pred = label\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './cut_dataset/'\n",
    "codebook_dtw = np.zeros((10,108*60,13))\n",
    "for label in range(10):  #Iterate over each digit\n",
    "    folder = os.path.join(directory,str(label)+'/')\n",
    "    i=0\n",
    "    for file in os.listdir(folder):\n",
    "        fs, digit1 = read(folder+file)\n",
    "        digit = digit1/max(abs(digit1))  #Scale the audio file\n",
    "        features=np.array(feature_extractor(digit))\n",
    "        codebook_dtw[label,i*60:(i+1)*60,:] = features\n",
    "        i+=1\n",
    "    print('done', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "target_list = []\n",
    "for test in range(27):\n",
    "    print(test)\n",
    "    cb, testset = split_codebook(codebook_dtw, test)\n",
    "    for label in range(10):  #Iterate over each digit\n",
    "        print(label)\n",
    "        for i in range(4):  #Size of testset\n",
    "            test_features = testset[label, i*60:(i+1)*60:]\n",
    "            pred = predict_with_DTW(test_features, cb)\n",
    "            pred_list.append(pred)\n",
    "            target_list.append(label)\n",
    "accuracy = get_accuracy(target_list, pred_list)  \n",
    "print(\"\\nAccuracy = \", accuracy)\n",
    "conf = confusion_matrix(target_list, pred_list)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
